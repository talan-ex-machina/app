import google.generativeai as genai
import json
import datetime
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY
from reportlab.lib.colors import HexColor
from reportlab.lib.units import inch


API_KEY = "AIzaSyA34Pv0jIWHZDxtYP1mIt5_qUM6vn8kHTU"

genai.configure(api_key=API_KEY)



model = genai.GenerativeModel("gemini-1.5-flash")

# Charge le JSON statistiques (le plus r√©cent)
import glob
import os

def find_latest_resume_file():
    """Trouve le fichier resume_structure.json le plus r√©cent dans tous les dossiers d'analyse"""
    # Chercher dans tous les dossiers analyse_*
    all_resume_files = []
    
    # Chercher dans le r√©pertoire courant
    current_dir_files = glob.glob("resume_structure*.json")
    all_resume_files.extend(current_dir_files)
    
    # Chercher dans les dossiers analyse_*
    analysis_dirs = glob.glob("analyse_*")
    for dir_name in analysis_dirs:
        pattern = os.path.join(dir_name, "resume_structure*.json")
        dir_files = glob.glob(pattern)
        all_resume_files.extend(dir_files)
    
    if all_resume_files:
        # Prendre le plus r√©cent bas√© sur la date de modification
        latest_resume = max(all_resume_files, key=os.path.getctime)
        print(f"‚úÖ Utilisation du resume: {latest_resume}")
        return latest_resume
    else:
        # Fallback vers le fichier par d√©faut
        fallback_file = "resume_structure.json"
        print(f"‚ö†Ô∏è Aucun fichier resume trouv√©, tentative: {fallback_file}")
        return fallback_file

def load_analysis_data():
    """Charge les donn√©es d'analyse avec gestion d'erreurs"""
    try:
        latest_resume = find_latest_resume_file()
        
        if not os.path.exists(latest_resume):
            raise FileNotFoundError(f"Fichier introuvable: {latest_resume}")
            
        with open(latest_resume, "r", encoding='utf-8') as f:
            stats = json.load(f)
            print(f"‚úÖ Donn√©es charg√©es: {len(stats)} sections")
            return stats
            
    except FileNotFoundError as e:
        print(f"‚ùå ERREUR: {e}")
        print("üí° Assurez-vous d'avoir ex√©cut√© data.py avant reporter.py")
        return None
    except json.JSONDecodeError as e:
        print(f"‚ùå ERREUR JSON: {e}")
        print("üí° Le fichier JSON est corrompu")
        return None
    except Exception as e:
        print(f"‚ùå ERREUR inattendue: {e}")
        return None

# Charger les donn√©es d'analyse seulement si ex√©cut√© directement
if __name__ == "__main__":
    stats = load_analysis_data()
    if not stats:
        print("‚ùå Impossible de continuer sans donn√©es d'analyse")
        exit(1)
else:
    # Quand import√© comme module, ne pas ex√©cuter le code principal
    stats = None

# Analyse des donn√©es pour cr√©er un prompt plus d√©taill√©
def analyze_data_structure(data):
    analysis = {}
    
    # Analyse temporelle avec les 5 groupes
    def analyze_group_evolution(category_data):
        if not category_data:
            return {}
        
        evolution = {}
        for i, group in enumerate(category_data):
            group_name = f"groupe_{i+1}"
            evolution[group_name] = {
                "range": group.get('range', ''),
                "frames_count": group.get('frames_count', 0),
                "confidence": group.get('confidence', 0),
                "timestamp": group.get('timestamp', 0)
            }
        return evolution
    
    # Analyse des expressions faciales avec √©volution temporelle
    if 'face_analysis' in data and data['face_analysis']:
        face_groups = data['face_analysis']
        analysis['facial_expressions'] = {
            'evolution': analyze_group_evolution(face_groups),
            'overall_patterns': {},
            'critical_moments': []
        }
        
        # Analyse des patterns globaux
        avg_confidence = sum(g.get('confidence', 0) for g in face_groups) / len(face_groups)
        avg_smile = sum(g.get('is_smiling', 0) for g in face_groups) / len(face_groups)
        avg_eye_openness = sum(g.get('eye_openness', 0) for g in face_groups) / len(face_groups)
        
        analysis['facial_expressions']['overall_patterns'] = {
            'avg_confidence': avg_confidence,
            'smile_consistency': avg_smile,
            'eye_alertness': avg_eye_openness,
            'expression_variety': len(set(g.get('expression_category', '').split('/')[0].split('%')[-1] for g in face_groups))
        }
        
        # Identifier les moments critiques
        for i, group in enumerate(face_groups):
            confidence = group.get('confidence', 0)
            smile = group.get('is_smiling', 0)
            eye_contact = group.get('good_eye_contact', '0%true')
            
            if confidence < 0.8 or '0%true' in eye_contact:
                analysis['facial_expressions']['critical_moments'].append({
                    'group': i+1,
                    'issue': 'low_confidence' if confidence < 0.8 else 'no_eye_contact',
                    'range': group.get('range', ''),
                    'severity': 'high' if confidence < 0.5 else 'medium'
                })
    
    # Analyse du contact visuel avec tendances
    if 'eye_contact' in data and data['eye_contact']:
        eye_groups = data['eye_contact']
        analysis['gaze_analysis'] = {
            'evolution': analyze_group_evolution(eye_groups),
            'consistency_score': 0,
            'direction_stability': {},
            'engagement_level': 'low'
        }
        
        # Calculer la consistance du regard
        good_contact_scores = []
        for group in eye_groups:
            # Extraire le pourcentage de bon contact visuel
            contact_str = group.get('good_eye_contact', '0%true')
            if '%true' in contact_str:
                pct = int(contact_str.split('%')[0])
                good_contact_scores.append(pct)
        
        if good_contact_scores:
            analysis['gaze_analysis']['consistency_score'] = sum(good_contact_scores) / len(good_contact_scores)
            if analysis['gaze_analysis']['consistency_score'] > 70:
                analysis['gaze_analysis']['engagement_level'] = 'high'
            elif analysis['gaze_analysis']['consistency_score'] > 30:
                analysis['gaze_analysis']['engagement_level'] = 'medium'
    
    # Analyse de la posture avec stabilit√©
    if 'pose_analysis' in data and data['pose_analysis']:
        pose_groups = data['pose_analysis']
        analysis['body_language'] = {
            'evolution': analyze_group_evolution(pose_groups),
            'stability_metrics': {},
            'energy_level': 'neutral'
        }
        
        # Calculer les m√©triques de stabilit√©
        head_tilts = [abs(g.get('head_tilt', 0)) for g in pose_groups]
        shoulder_tilts = [abs(g.get('shoulder_tilt', 0)) for g in pose_groups]
        
        if head_tilts:
            analysis['body_language']['stability_metrics'] = {
                'head_stability': max(head_tilts) - min(head_tilts),
                'avg_head_tilt': sum(head_tilts) / len(head_tilts),
                'posture_consistency': 100 - (max(head_tilts) - min(head_tilts)) * 2
            }
    
    # Analyse des gestes avec activit√©
    if 'hand_analysis' in data and data['hand_analysis']:
        hand_groups = data['hand_analysis']
        analysis['gesture_dynamics'] = {
            'evolution': analyze_group_evolution(hand_groups),
            'activity_patterns': {},
            'communication_style': 'passive'
        }
        
        # Analyser les patterns d'activit√©
        activity_levels = [g.get('activity_level', 0) for g in hand_groups]
        if activity_levels:
            avg_activity = sum(activity_levels) / len(activity_levels)
            analysis['gesture_dynamics']['activity_patterns'] = {
                'average_activity': avg_activity,
                'peak_activity': max(activity_levels),
                'consistency': 100 - (max(activity_levels) - min(activity_levels)) * 50
            }
            
            if avg_activity > 0.7:
                analysis['gesture_dynamics']['communication_style'] = 'very_active'
            elif avg_activity > 0.4:
                analysis['gesture_dynamics']['communication_style'] = 'active'
            elif avg_activity > 0.2:
                analysis['gesture_dynamics']['communication_style'] = 'moderate'
    
    # M√©tadonn√©es enrichies
    metadata = data.get('metadata', {})
    analysis['session_context'] = {
        'duration': metadata.get('duration', 0),
        'total_frames': metadata.get('total_frames', 0),
        'fps': metadata.get('fps', 0),
        'processing_method': metadata.get('processing_method', 'unknown'),
        'analysis_depth': 'comprehensive_5_groups'
    }
    
    return analysis

# Ex√©cuter seulement si appel√© directement, pas lors d'un import
if __name__ == "__main__":
    detailed_analysis = analyze_data_structure(stats)

    # Pr√©pare le prompt optimis√© avec analyse temporelle
    prompt = f"""
Tu es un expert en communication non verbale et analyse comportementale. Analyse cette session de {stats.get('metadata', {}).get('duration', 'N/A')}s divis√©e en 5 segments temporels.

CONTEXTE DE LA SESSION :
- Dur√©e : {detailed_analysis.get('session_context', {}).get('duration', 'N/A')} secondes
- M√©thode d'analyse : {detailed_analysis.get('session_context', {}).get('processing_method', 'N/A')}
- Profondeur : Analyse segment√©e en 5 groupes temporels

ANALYSE TEMPORELLE D√âTAILL√âE :

üéØ EXPRESSIONS FACIALES (√âvolution temporelle)
Patterns globaux :
- Confiance moyenne : {detailed_analysis.get('facial_expressions', {}).get('overall_patterns', {}).get('avg_confidence', 0)*100:.1f}%
- Consistance sourire : {detailed_analysis.get('facial_expressions', {}).get('overall_patterns', {}).get('smile_consistency', 0)*100:.1f}%
- Vigilance oculaire : {detailed_analysis.get('facial_expressions', {}).get('overall_patterns', {}).get('eye_alertness', 0)*100:.1f}%
- Vari√©t√© expressions : {detailed_analysis.get('facial_expressions', {}).get('overall_patterns', {}).get('expression_variety', 0)} types

Moments critiques identifi√©s : {len(detailed_analysis.get('facial_expressions', {}).get('critical_moments', []))} incidents

üëÅÔ∏è CONTACT VISUEL (Performance)
- Score de consistance : {detailed_analysis.get('gaze_analysis', {}).get('consistency_score', 0):.1f}%
- Niveau d'engagement : {detailed_analysis.get('gaze_analysis', {}).get('engagement_level', 'N/A')}
- √âvolution sur 5 segments : {len(detailed_analysis.get('gaze_analysis', {}).get('evolution', {}))} mesures

üèÉ LANGAGE CORPOREL (Stabilit√©)
M√©triques de stabilit√© :
- Stabilit√© t√™te : {detailed_analysis.get('body_language', {}).get('stability_metrics', {}).get('head_stability', 0):.1f}¬∞
- Inclinaison moyenne : {detailed_analysis.get('body_language', {}).get('stability_metrics', {}).get('avg_head_tilt', 0):.1f}¬∞
- Consistance posture : {detailed_analysis.get('body_language', {}).get('stability_metrics', {}).get('posture_consistency', 0):.1f}%

‚ö° DYNAMIQUE GESTUELLE
Patterns d'activit√© :
- Activit√© moyenne : {detailed_analysis.get('gesture_dynamics', {}).get('activity_patterns', {}).get('average_activity', 0)*100:.1f}%
- Pic d'activit√© : {detailed_analysis.get('gesture_dynamics', {}).get('activity_patterns', {}).get('peak_activity', 0)*100:.1f}%
- Style communication : {detailed_analysis.get('gesture_dynamics', {}).get('communication_style', 'N/A')}

G√âN√àRE UN RAPPORT PROFESSIONNEL STRUCTUR√â :

üìà R√âSUM√â EX√âCUTIF
- Score global de performance /100 (justifie avec m√©triques pr√©cises)
- 3 forces majeures avec donn√©es quantifi√©es
- 3 axes d'am√©lioration prioritaires avec impact estim√©
- Recommandation strat√©gique principale

üìä ANALYSE TEMPORELLE SEGMENT√âE
- √âvolution des performances sur les 5 segments
- Identification des moments de pic et de creux
- Patterns comportementaux r√©currents
- Coh√©rence ou incoh√©rence dans la communication

üëÅÔ∏è IMPACT COMMUNICATIONNEL
- Cr√©dibilit√© per√ßue (facteurs quantifi√©s)
- Engagement audience (pr√©diction bas√©e donn√©es)
- Points de d√©crochage identifi√©s
- Recommandations correctives sp√©cifiques

üèÉ OPTIMISATION COMPORTEMENTALE
- Actions concr√®tes class√©es par priorit√©
- Timeline d'am√©lioration sugg√©r√©e
- M√©triques de suivi recommand√©es
- Techniques d'entra√Ænement sp√©cifiques

Sois pr√©cis, utilise les donn√©es quantifi√©es, propose des solutions actionnables et √©value l'impact business de chaque recommandation.
"""

    print("üìä Envoi de la demande √† l'IA Gemini...")
    print("‚è≥ G√©n√©ration en cours (peut prendre 10-30 secondes)...")

    try:
        response = model.generate_content(prompt)
        rapport = response.text
        print("‚úÖ R√©ponse IA re√ßue !")
        
    except Exception as e:
        print(f"‚ùå ERREUR lors de la g√©n√©ration IA: {e}")
        print("üí° V√©rifiez votre connexion internet et votre cl√© API")
        # Cr√©er un rapport de fallback basique
        rapport = f"""
        RAPPORT D'ANALYSE - MODE D√âGRAD√â
        
        üìà R√âSUM√â EX√âCUTIF
        Analyse technique compl√©t√©e sur {stats.get('metadata', {}).get('duration', 'N/A')} secondes.
        
        Donn√©es disponibles :
        - Frames analys√©es : {stats.get('metadata', {}).get('total_frames', 'N/A')}
        - FPS : {stats.get('metadata', {}).get('fps', 'N/A')}
        
        ‚ö†Ô∏è Analyse IA indisponible - Consultez les donn√©es JSON pour plus de d√©tails.
        """

    print("üìÑ G√©n√©ration du PDF en cours...")

    print("=" * 80)
    print("RAPPORT D'ANALYSE DE COMMUNICATION NON VERBALE - VERSION DETAILLEE")
    print("=" * 80)
    print(rapport)
    print("=" * 80)
    print(f" Donn√©es analys√©es : {stats.get('metadata', {}).get('total_frames', 'N/A')} frames sur {stats.get('metadata', {}).get('duration', 'N/A')}s")
    print(f" G√©n√©r√© le : {datetime.datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}")
    print("=" * 80)

def create_pdf_report(rapport_content, stats):
    """Cr√©e un rapport PDF professionnel avec horodatage"""
    try:
        # Cr√©er un nom de fichier avec horodatage
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"rapport_analyse_{timestamp}.pdf"
        
        # Cr√©er le document PDF
        doc = SimpleDocTemplate(filename, pagesize=A4,
                              rightMargin=72, leftMargin=72,
                              topMargin=72, bottomMargin=18)
        
        # Obtenir les styles par d√©faut
        styles = getSampleStyleSheet()
        
        # Cr√©er des styles personnalis√©s
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=TA_CENTER,
            textColor=HexColor('#2C3E50'),
            fontName='Helvetica-Bold'
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            spaceBefore=20,
            textColor=HexColor('#34495E'),
            fontName='Helvetica-Bold'
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontSize=11,
            spaceAfter=6,
            alignment=TA_JUSTIFY,
            fontName='Helvetica'
        )
        
        # Liste pour stocker les √©l√©ments du PDF
        story = []
        
        # Titre principal
        story.append(Paragraph("üìä RAPPORT D'ANALYSE DE COMMUNICATION NON VERBALE", title_style))
        story.append(Paragraph("VERSION D√âTAILL√âE", title_style))
        story.append(Spacer(1, 20))
        
        # Informations sur l'analyse
        info_text = f"""
         <b>Donn√©es analys√©es :</b> {stats.get('metadata', {}).get('total_frames', 'N/A')} frames sur {stats.get('metadata', {}).get('duration', 'N/A')} secondes<br/>
         <b>G√©n√©r√© le :</b> {datetime.datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}<br/>
         <b>FPS :</b> {stats.get('metadata', {}).get('fps', 'N/A')}
        """
        story.append(Paragraph(info_text, normal_style))
        story.append(Spacer(1, 30))
        
        # Traiter le contenu du rapport
        lines = rapport_content.split('\n')
        current_section = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                story.append(Spacer(1, 6))
                continue
                
            # D√©tecter les titres de section (avec emojis)
            if any(emoji in line for emoji in ['üéØ', 'üìä', 'üëÅÔ∏è', 'üèÉ', '‚ö°', 'üìà', 'üìã']):
                story.append(Spacer(1, 15))
                # Nettoyer les emojis pour le PDF
                clean_line = line.replace('üéØ', '‚ñ†').replace('üìä', '‚ñ†').replace('üëÅÔ∏è', '‚ñ†').replace('üèÉ', '‚ñ†').replace('‚ö°', '‚ñ†').replace('üìà', '‚ñ†').replace('üìã', '‚ñ†')
                story.append(Paragraph(clean_line, heading_style))
                current_section = line
            # Sous-titres avec tirets
            elif line.startswith('- ') and len(line) < 80:
                story.append(Paragraph(f"<b>{line}</b>", normal_style))
            # Points de liste avec puces
            elif line.startswith('SUCCES'):
                story.append(Paragraph(line, normal_style))
            # Texte normal
            else:
                # Remplacer les caract√®res sp√©ciaux pour PDF
                line = line.replace('¬∞', '&deg;').replace('‚Ä¢', '-')
                story.append(Paragraph(line, normal_style))
        
        # Construire le PDF
        doc.build(story)
        return filename
        
    except Exception as e:
        print(f"‚ùå ERREUR lors de la cr√©ation PDF: {e}")
        return None

if __name__ == "__main__":
    # G√©n√©rer le PDF avec gestion d'erreurs
    try:
        pdf_filename = create_pdf_report(rapport, stats)
        if pdf_filename:
            print(f"\n‚úÖ Rapport PDF sauvegard√© dans : {pdf_filename}")
        else:
            print("‚ùå √âchec de la cr√©ation du PDF")
    except Exception as e:
        print(f"‚ùå ERREUR lors de la g√©n√©ration du PDF: {e}")
        print("üí° V√©rifiez que ReportLab est install√© et que vous avez les permissions d'√©criture")
