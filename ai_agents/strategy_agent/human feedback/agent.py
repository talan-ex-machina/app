from typing import Dict, List, Any, Optional, TypedDict, Union
from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from dataclasses import dataclass
from enum import Enum
import json
import logging
import os
from datetime import datetime
import sys
from dotenv import load_dotenv

load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FeedbackType(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    SUGGESTION = "suggestion"
    QUESTION = "question"
    MIXED = "mixed"

class StrategyElementType(Enum):
    TEXT = "text"
    LIST = "list"
    DICT = "dict"
    NUMBER = "number"
    BOOLEAN = "boolean"
    DATE = "date"
    COMPLEX = "complex"

@dataclass
class StrategyElement:
    """Repr√©sente un √©l√©ment de strat√©gie avec ses m√©tadonn√©es"""
    path: str  # Chemin dans la structure (ex: "budget.marketing.digital")
    value: Any
    element_type: StrategyElementType
    parent_path: Optional[str] = None
    description: Optional[str] = None

@dataclass
class FeedbackAnalysis:
    sentiment: str
    feedback_type: FeedbackType
    affected_elements: List[StrategyElement]
    key_issues: List[str]
    suggestions: List[str]
    confidence_score: float
    feedback_complexity: str  # simple, moderate, complex
    
@dataclass
class StrategyAdjustment:
    element_path: str
    original_value: Any
    adjusted_value: Any
    reason: str
    priority: int
    adjustment_type: str  # "modify", "add", "remove", "restructure"
    impact_level: str  # "low", "medium", "high"

class FeedbackState(TypedDict):
    original_strategy: Dict[str, Any]
    human_feedback: str
    strategy_structure: Dict[str, StrategyElement]
    feedback_analysis: Optional[FeedbackAnalysis]
    strategy_adjustments: List[StrategyAdjustment]
    adjusted_strategy: Optional[Dict[str, Any]]
    iteration_count: int
    processing_metadata: Dict[str, Any]

class GeneralizedHumanFeedbackAgent:
    def __init__(self, gemini_api_key: str = None, model_name: str = "gemini-2.0-flash-exp"):
        """
        Initialise l'agent de feedback humain g√©n√©ralis√©
        
        Args:
            gemini_api_key: Cl√© API Gemini (utilise la variable d'environnement si None)
            model_name: Nom du mod√®le Gemini √† utiliser
        """
        api_key = gemini_api_key or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY doit √™tre fournie soit comme param√®tre soit comme variable d'environnement")
            
        self.llm = ChatGoogleGenerativeAI(
            google_api_key=api_key,
            model=model_name,
            temperature=0.3,
            max_output_tokens=4096
        )
        
        # Construction du workflow LangGraph
        self.workflow = self._build_workflow()
        
    def _build_workflow(self) -> StateGraph:
        """Construit le workflow LangGraph pour l'analyse du feedback"""
        
        workflow = StateGraph(FeedbackState)
        
        # Ajout des n≈ìuds
        workflow.add_node("analyze_structure", self._analyze_strategy_structure)
        workflow.add_node("analyze_feedback", self._analyze_feedback)
        workflow.add_node("identify_elements", self._identify_affected_elements)
        workflow.add_node("generate_adjustments", self._generate_adjustments)
        workflow.add_node("apply_adjustments", self._apply_adjustments)
        workflow.add_node("validate_strategy", self._validate_adjusted_strategy)
        
        # D√©finition des transitions
        workflow.add_edge("analyze_structure", "analyze_feedback")
        workflow.add_edge("analyze_feedback", "identify_elements")
        workflow.add_edge("identify_elements", "generate_adjustments")
        workflow.add_edge("generate_adjustments", "apply_adjustments")
        workflow.add_edge("apply_adjustments", "validate_strategy")
        workflow.add_edge("validate_strategy", END)
        
        # Point d'entr√©e
        workflow.set_entry_point("analyze_structure")
        
        return workflow.compile()
    
    def _analyze_strategy_structure(self, state: FeedbackState) -> Dict[str, Any]:
        """Analyse la structure de la strat√©gie pour comprendre ses composants"""
        
        strategy = state["original_strategy"]
        structure_elements = {}
        
        def analyze_element(value: Any, path: str, parent_path: Optional[str] = None) -> StrategyElement:
            """Analyse r√©cursivement chaque √©l√©ment de la strat√©gie"""
            
            if isinstance(value, dict):
                element = StrategyElement(
                    path=path,
                    value=value,
                    element_type=StrategyElementType.DICT,
                    parent_path=parent_path
                )
                # Analyser les sous-√©l√©ments
                for key, sub_value in value.items():
                    sub_path = f"{path}.{key}" if path else key
                    analyze_element(sub_value, sub_path, path)
                    
            elif isinstance(value, list):
                element = StrategyElement(
                    path=path,
                    value=value,
                    element_type=StrategyElementType.LIST,
                    parent_path=parent_path
                )
                # Analyser les √©l√©ments de la liste
                for i, item in enumerate(value):
                    item_path = f"{path}[{i}]"
                    analyze_element(item, item_path, path)
                    
            elif isinstance(value, (int, float)):
                element = StrategyElement(
                    path=path,
                    value=value,
                    element_type=StrategyElementType.NUMBER,
                    parent_path=parent_path
                )
                
            elif isinstance(value, bool):
                element = StrategyElement(
                    path=path,
                    value=value,
                    element_type=StrategyElementType.BOOLEAN,
                    parent_path=parent_path
                )
                
            elif isinstance(value, str):
                # D√©tecter si c'est une date
                if self._is_date_string(value):
                    element = StrategyElement(
                        path=path,
                        value=value,
                        element_type=StrategyElementType.DATE,
                        parent_path=parent_path
                    )
                else:
                    element = StrategyElement(
                        path=path,
                        value=value,
                        element_type=StrategyElementType.TEXT,
                        parent_path=parent_path
                    )
            else:
                element = StrategyElement(
                    path=path,
                    value=value,
                    element_type=StrategyElementType.COMPLEX,
                    parent_path=parent_path
                )
            
            structure_elements[path] = element
            return element
        
        # Analyser la structure compl√®te
        for key, value in strategy.items():
            analyze_element(value, key)
        
        logger.info(f"Structure analys√©e: {len(structure_elements)} √©l√©ments identifi√©s")
        
        return {**state, "strategy_structure": structure_elements}
    
    def _is_date_string(self, text: str) -> bool:
        """D√©tecte si une cha√Æne repr√©sente une date"""
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{2}/\d{2}/\d{4}',  # DD/MM/YYYY
            r'\d{1,2} mois',        # X mois
            r'\d{1,2} ans?',        # X an(s)
            r'janvier|f√©vrier|mars|avril|mai|juin|juillet|ao√ªt|septembre|octobre|novembre|d√©cembre'
        ]
        
        import re
        for pattern in date_patterns:
            if re.search(pattern, text.lower()):
                return True
        return False
    
    def _analyze_feedback(self, state: FeedbackState) -> Dict[str, Any]:
        """Analyse le feedback humain de mani√®re g√©n√©rale"""
        
        feedback = state["human_feedback"]
        strategy_summary = self._generate_strategy_summary(state["original_strategy"])
        
        analysis_prompt = f"""
        Tu es un expert en analyse de feedback utilisateur pour les strat√©gies business. 
        Analyse ce feedback sur une strat√©gie quelconque :
        
        R√âSUM√â DE LA STRAT√âGIE: {strategy_summary}
        
        FEEDBACK UTILISATEUR: "{feedback}"
        
        Analyse ce feedback selon ces crit√®res :
        
        1. SENTIMENT (positif/n√©gatif/neutre/mixte)
        2. TYPE DE FEEDBACK (positive/negative/suggestion/question/mixed)
        3. COMPLEXIT√â DU FEEDBACK (simple/moderate/complex)
        4. PROBL√àMES IDENTIFI√âS (sois sp√©cifique)
        5. SUGGESTIONS IMPLICITES OU EXPLICITES
        6. NIVEAU DE CONFIANCE dans ton analyse (0-1)
        
        R√©ponds en JSON structur√© :
        {{
            "sentiment": "...",
            "feedback_type": "...",
            "feedback_complexity": "...",
            "key_issues": ["issue1", "issue2", ...],
            "suggestions": ["suggestion1", "suggestion2", ...],
            "confidence_score": 0.85
        }}
        """
        
        try:
            response = self.llm.invoke(analysis_prompt)
            analysis_data = json.loads(response.content)
            
            feedback_analysis = FeedbackAnalysis(
                sentiment=analysis_data["sentiment"],
                feedback_type=FeedbackType(analysis_data["feedback_type"]),
                affected_elements=[],  # Sera rempli dans la prochaine √©tape
                key_issues=analysis_data["key_issues"],
                suggestions=analysis_data["suggestions"],
                confidence_score=analysis_data["confidence_score"],
                feedback_complexity=analysis_data.get("feedback_complexity", "moderate")
            )
            
            logger.info(f"Feedback analys√© - Sentiment: {feedback_analysis.sentiment}, Confiance: {feedback_analysis.confidence_score}")
            
            return {**state, "feedback_analysis": feedback_analysis}
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse du feedback: {e}")
            # Analyse par d√©faut
            default_analysis = FeedbackAnalysis(
                sentiment="neutre",
                feedback_type=FeedbackType.MIXED,
                affected_elements=[],
                key_issues=["Analyse automatique √©chou√©e"],
                suggestions=["R√©viser le feedback manuellement"],
                confidence_score=0.1,
                feedback_complexity="moderate"
            )
            return {**state, "feedback_analysis": default_analysis}
    
    def _generate_strategy_summary(self, strategy: Dict[str, Any]) -> str:
        """G√©n√®re un r√©sum√© de la strat√©gie pour le contexte"""
        try:
            summary_parts = []
            
            def summarize_element(key: str, value: Any, depth: int = 0) -> str:
                indent = "  " * depth
                if isinstance(value, dict):
                    sub_items = [f"{k}: {type(v).__name__}" for k, v in value.items()]
                    return f"{indent}{key}: {{{', '.join(sub_items[:3])}{', ...' if len(sub_items) > 3 else '}'}"
                elif isinstance(value, list):
                    return f"{indent}{key}: liste de {len(value)} √©l√©ments"
                else:
                    preview = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                    return f"{indent}{key}: {preview}"
            
            for key, value in strategy.items():
                summary_parts.append(summarize_element(key, value))
            
            return "\n".join(summary_parts)
            
        except Exception:
            return "Structure complexe non r√©sumable"
    
    def _identify_affected_elements(self, state: FeedbackState) -> Dict[str, Any]:
        """Identifie quels √©l√©ments de la strat√©gie sont affect√©s par le feedback"""
        
        feedback = state["human_feedback"]
        structure_elements = state["strategy_structure"]
        feedback_analysis = state["feedback_analysis"]
        
        # Cr√©er une liste descriptive des √©l√©ments pour l'IA
        elements_description = []
        for path, element in structure_elements.items():
            description = f"- {path} ({element.element_type.value}): {str(element.value)[:100]}..."
            elements_description.append(description)
        
        identification_prompt = f"""
        Tu es un expert en analyse de strat√©gies. Identifie quels √©l√©ments sp√©cifiques de cette strat√©gie 
        sont affect√©s par le feedback utilisateur.
        
        FEEDBACK: "{feedback}"
        
        PROBL√àMES IDENTIFI√âS: {feedback_analysis.key_issues}
        SUGGESTIONS: {feedback_analysis.suggestions}
        
        √âL√âMENTS DE LA STRAT√âGIE:
        {chr(10).join(elements_description)}
        
        Retourne une liste JSON des chemins d'√©l√©ments affect√©s (exemple: ["budget", "timeline.duration", "objectives[0]"]):
        """
        
        try:
            response = self.llm.invoke(identification_prompt)
            affected_paths = json.loads(response.content)
            
            # Filtrer les chemins valides et cr√©er les √©l√©ments affect√©s
            affected_elements = []
            for path in affected_paths:
                if path in structure_elements:
                    affected_elements.append(structure_elements[path])
                else:
                    # Recherche approximative pour les chemins partiels
                    for element_path, element in structure_elements.items():
                        if path in element_path or element_path in path:
                            affected_elements.append(element)
                            break
            
            feedback_analysis.affected_elements = affected_elements
            
            logger.info(f"√âl√©ments affect√©s identifi√©s: {[e.path for e in affected_elements]}")
            
            return {**state, "feedback_analysis": feedback_analysis}
            
        except Exception as e:
            logger.error(f"Erreur lors de l'identification des √©l√©ments: {e}")
            # Par d√©faut, s√©lectionner les premiers √©l√©ments
            feedback_analysis.affected_elements = list(structure_elements.values())[:3]
            return {**state, "feedback_analysis": feedback_analysis}
    
    def _generate_adjustments(self, state: FeedbackState) -> Dict[str, Any]:
        """G√©n√®re les ajustements sp√©cifiques pour chaque √©l√©ment affect√©"""
        
        feedback_analysis = state["feedback_analysis"]
        original_strategy = state["original_strategy"]
        feedback = state["human_feedback"]
        
        adjustments = []
        
        for element in feedback_analysis.affected_elements:
            adjustment_prompt = f"""
            Tu es un consultant en strat√©gie. G√©n√®re un ajustement sp√©cifique pour l'√©l√©ment de strat√©gie suivant 
            bas√© sur le feedback utilisateur.
            
            FEEDBACK UTILISATEUR: "{feedback}"
            PROBL√àMES IDENTIFI√âS: {feedback_analysis.key_issues}
            SUGGESTIONS: {feedback_analysis.suggestions}
            
            √âL√âMENT √Ä AJUSTER:
            - Chemin: {element.path}
            - Type: {element.element_type.value}
            - Valeur actuelle: {element.value}
            
            G√©n√®re un ajustement en JSON :
            {{
                "original_value": "valeur actuelle...",
                "adjusted_value": "valeur ajust√©e...",
                "reason": "explication d√©taill√©e de l'ajustement...",
                "priority": 1-5,
                "adjustment_type": "modify/add/remove/restructure",
                "impact_level": "low/medium/high"
            }}
            
            IMPORTANT: 
            - La valeur ajust√©e doit respecter le type d'origine
            - L'ajustement doit √™tre sp√©cifique et actionnable
            - Maintenir la coh√©rence avec le reste de la strat√©gie
            """
            
            try:
                response = self.llm.invoke(adjustment_prompt)
                adjustment_data = json.loads(response.content)
                
                adjustment = StrategyAdjustment(
                    element_path=element.path,
                    original_value=adjustment_data["original_value"],
                    adjusted_value=adjustment_data["adjusted_value"],
                    reason=adjustment_data["reason"],
                    priority=adjustment_data["priority"],
                    adjustment_type=adjustment_data.get("adjustment_type", "modify"),
                    impact_level=adjustment_data.get("impact_level", "medium")
                )
                
                adjustments.append(adjustment)
                logger.info(f"Ajustement g√©n√©r√© pour {element.path} (priorit√©: {adjustment.priority})")
                
            except Exception as e:
                logger.error(f"Erreur lors de la g√©n√©ration d'ajustement pour {element.path}: {e}")
                continue
        
        # Tri par priorit√© et impact
        adjustments.sort(key=lambda x: (x.priority, {"high": 1, "medium": 2, "low": 3}[x.impact_level]))
        
        return {**state, "strategy_adjustments": adjustments}
    
    def _apply_adjustments(self, state: FeedbackState) -> Dict[str, Any]:
        """Applique les ajustements √† la strat√©gie de mani√®re intelligente"""
        
        adjusted_strategy = self._deep_copy_strategy(state["original_strategy"])
        adjustments = state["strategy_adjustments"]
        
        applied_adjustments = []
        
        for adjustment in adjustments:
            try:
                success = self._apply_single_adjustment(adjusted_strategy, adjustment)
                if success:
                    applied_adjustments.append(adjustment)
                    logger.info(f"Ajustement appliqu√© avec succ√®s: {adjustment.element_path}")
                else:
                    logger.warning(f"√âchec de l'application de l'ajustement: {adjustment.element_path}")
                    
            except Exception as e:
                logger.error(f"Erreur lors de l'application de l'ajustement {adjustment.element_path}: {e}")
        
        # Ajout des m√©tadonn√©es
        metadata = {
            "adjustments_applied": len(applied_adjustments),
            "total_adjustments_attempted": len(adjustments),
            "iteration": state.get("iteration_count", 1),
            "feedback_confidence": state["feedback_analysis"].confidence_score,
            "feedback_complexity": state["feedback_analysis"].feedback_complexity,
            "adjustments_summary": [
                {
                    "path": adj.element_path,
                    "type": adj.adjustment_type,
                    "reason": adj.reason,
                    "priority": adj.priority,
                    "impact": adj.impact_level
                } for adj in applied_adjustments
            ],
            "timestamp": datetime.now().isoformat()
        }
        
        # Ajouter les m√©tadonn√©es sans √©craser la structure existante
        if isinstance(adjusted_strategy, dict):
            adjusted_strategy["_feedback_metadata"] = metadata
        
        return {
            **state, 
            "adjusted_strategy": adjusted_strategy,
            "processing_metadata": metadata
        }
    
    def _deep_copy_strategy(self, strategy: Any) -> Any:
        """Copie profonde de la strat√©gie"""
        if isinstance(strategy, dict):
            return {k: self._deep_copy_strategy(v) for k, v in strategy.items()}
        elif isinstance(strategy, list):
            return [self._deep_copy_strategy(item) for item in strategy]
        else:
            return strategy
    
    def _apply_single_adjustment(self, strategy: Dict[str, Any], adjustment: StrategyAdjustment) -> bool:
        """Applique un ajustement unique √† la strat√©gie"""
        
        path_parts = adjustment.element_path.split('.')
        current = strategy
        
        try:
            # Naviguer jusqu'au parent de l'√©l√©ment √† modifier
            for i, part in enumerate(path_parts[:-1]):
                if '[' in part and ']' in part:
                    # Gestion des indices de liste
                    key, index_str = part.split('[')
                    index = int(index_str.rstrip(']'))
                    current = current[key][index]
                else:
                    current = current[part]
            
            # Appliquer l'ajustement
            final_key = path_parts[-1]
            
            if '[' in final_key and ']' in final_key:
                # Gestion des indices de liste
                key, index_str = final_key.split('[')
                index = int(index_str.rstrip(']'))
                
                if adjustment.adjustment_type == "remove":
                    current[key].pop(index)
                elif adjustment.adjustment_type == "add":
                    current[key].insert(index, adjustment.adjusted_value)
                else:
                    current[key][index] = adjustment.adjusted_value
            else:
                if adjustment.adjustment_type == "remove":
                    current.pop(final_key, None)
                elif adjustment.adjustment_type == "add":
                    current[final_key] = adjustment.adjusted_value
                else:
                    current[final_key] = adjustment.adjusted_value
            
            return True
            
        except (KeyError, IndexError, ValueError, TypeError) as e:
            logger.error(f"Erreur lors de l'application de l'ajustement {adjustment.element_path}: {e}")
            return False
    
    def _validate_adjusted_strategy(self, state: FeedbackState) -> Dict[str, Any]:
        """Valide la coh√©rence de la strat√©gie ajust√©e de mani√®re g√©n√©rale"""
        
        adjusted_strategy = state["adjusted_strategy"]
        original_strategy = state["original_strategy"]
        
        validation_prompt = f"""
        Tu es un expert en validation de strat√©gies. √âvalue la qualit√© et la coh√©rence de cette strat√©gie ajust√©e 
        par rapport √† l'originale.
        
        STRAT√âGIE ORIGINALE: {json.dumps(original_strategy, indent=2, ensure_ascii=False)[:1000]}...
        
        STRAT√âGIE AJUST√âE: {json.dumps(adjusted_strategy, indent=2, ensure_ascii=False)[:1000]}...
        
        √âvalue selon ces crit√®res :
        1. Coh√©rence interne entre les diff√©rents √©l√©ments
        2. Pr√©servation de la structure logique
        3. R√©alisme et faisabilit√© des modifications
        4. Am√©lioration par rapport √† l'original
        5. Compl√©tude de l'information
        
        Retourne ton √©valuation en JSON :
        {{
            "validation_score": 8.5,
            "is_valid": true,
            "coherence_score": 0.9,
            "improvement_score": 0.8,
            "feasibility_score": 0.85,
            "comments": ["commentaire1", "commentaire2"],
            "recommendations": ["am√©lioration1", "am√©lioration2"],
            "critical_issues": ["probl√®me critique si il y en a"]
        }}
        """
        
        try:
            response = self.llm.invoke(validation_prompt)
            validation_data = json.loads(response.content)
            
            # Mise √† jour des m√©tadonn√©es
            processing_metadata = state.get("processing_metadata", {})
            processing_metadata["validation"] = validation_data
            
            # Ajout aux m√©tadonn√©es de la strat√©gie si possible
            if isinstance(adjusted_strategy, dict) and "_feedback_metadata" in adjusted_strategy:
                adjusted_strategy["_feedback_metadata"]["validation"] = validation_data
            
            logger.info(f"Validation termin√©e - Score: {validation_data.get('validation_score', 'N/A')}/10")
            
            return {
                **state, 
                "adjusted_strategy": adjusted_strategy,
                "processing_metadata": processing_metadata
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la validation: {e}")
            
            # Validation par d√©faut
            default_validation = {
                "validation_score": 6.0,
                "is_valid": True,
                "coherence_score": 0.7,
                "improvement_score": 0.6,
                "feasibility_score": 0.7,
                "comments": ["Validation automatique limit√©e"],
                "recommendations": ["R√©vision manuelle recommand√©e"],
                "critical_issues": []
            }
            
            processing_metadata = state.get("processing_metadata", {})
            processing_metadata["validation"] = default_validation
            
            return {
                **state,
                "processing_metadata": processing_metadata
            }
    
    def process_feedback(self, original_strategy: Union[Dict[str, Any], List, str], human_feedback: str) -> Dict[str, Any]:
        """
        Point d'entr√©e principal pour traiter le feedback humain sur n'importe quelle strat√©gie
        
        Args:
            original_strategy: La strat√©gie originale (peut √™tre dict, list, ou autre structure)
            human_feedback: Le feedback de l'utilisateur
            
        Returns:
            Dict contenant la strat√©gie ajust√©e et toutes les m√©tadonn√©es
        """
        
        # Normaliser la strat√©gie en dictionnaire si n√©cessaire
        if not isinstance(original_strategy, dict):
            if isinstance(original_strategy, list):
                normalized_strategy = {"strategy_elements": original_strategy}
            elif isinstance(original_strategy, str):
                normalized_strategy = {"strategy_content": original_strategy}
            else:
                normalized_strategy = {"strategy_data": original_strategy}
        else:
            normalized_strategy = original_strategy
        
        initial_state = FeedbackState(
            original_strategy=normalized_strategy,
            human_feedback=human_feedback,
            strategy_structure={},
            feedback_analysis=None,
            strategy_adjustments=[],
            adjusted_strategy=None,
            iteration_count=1,
            processing_metadata={}
        )
        
        logger.info(f"D√©marrage du traitement du feedback pour une strat√©gie de type {type(original_strategy).__name__}")
        
        try:
            # Ex√©cution du workflow
            final_state = self.workflow.invoke(initial_state)
            
            # Construction du r√©sultat final
            result = {
                "success": True,
                "adjusted_strategy": final_state["adjusted_strategy"],
                "feedback_analysis": {
                    "sentiment": final_state["feedback_analysis"].sentiment,
                    "feedback_type": final_state["feedback_analysis"].feedback_type.value,
                    "complexity": final_state["feedback_analysis"].feedback_complexity,
                    "key_issues": final_state["feedback_analysis"].key_issues,
                    "suggestions": final_state["feedback_analysis"].suggestions,
                    "confidence_score": final_state["feedback_analysis"].confidence_score,
                    "affected_elements": [e.path for e in final_state["feedback_analysis"].affected_elements]
                },
                "processing_metadata": final_state["processing_metadata"],
                "strategy_structure_info": {
                    "total_elements": len(final_state["strategy_structure"]),
                    "element_types": list(set(e.element_type.value for e in final_state["strategy_structure"].values())),
                    "affected_elements_count": len(final_state["feedback_analysis"].affected_elements)
                }
            }
            
            logger.info("Traitement du feedback termin√© avec succ√®s")
            return result
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement du feedback: {e}")
            return {
                "success": False,
                "error": str(e),
                "original_strategy": original_strategy,
                "feedback": human_feedback
            }

# Fonction utilitaire pour tester diff√©rents types de strat√©gies
def test_agent_with_different_strategies():
    """Teste l'agent avec diff√©rents types de strat√©gies"""
    
    feedback_agent = GeneralizedHumanFeedbackAgent()
    
    # Test 1: Strat√©gie business classique
    business_strategy = {
        "objectifs": "Augmenter les ventes de 20% en 6 mois",
        "plan_action": [
            "Analyse du march√©",
            "Optimisation marketing",
            "Formation √©quipe"
        ],
        "budget": {"total": 50000, "marketing": 30000, "formation": 20000},
        "timeline": "6 mois",
        "kpis": ["chiffre d'affaires", "taux de conversion", "satisfaction client"]
    }
    
    # Test 2: Strat√©gie produit
    product_strategy = {
        "product_vision": "Plateforme d'apprentissage innovante",
        "features": {
            "core": ["personalisation", "analytics", "collaboration"],
            "advanced": ["AI recommendations", "integration APIs"]
        },
        "roadmap": [
            {"phase": "MVP", "duration": "3 mois", "features": ["core"]},
            {"phase": "V2", "duration": "6 mois", "features": ["advanced"]}
        ],
        "target_audience": {
            "primary": "Entreprises 50-500 employ√©s",
            "secondary": "Consultants formation"
        }
    }
    
    # Test 3: Strat√©gie simple (liste)
    simple_strategy = [
        "√âtape 1: Recherche march√©",
        "√âtape 2: D√©veloppement prototype",
        "√âtape 3: Tests utilisateurs",
        "√âtape 4: Lancement"
    ]
    
    feedback = "Cette approche semble trop ambitieuse en termes de d√©lais. Il faudrait plus de r√©alisme dans la planification et pr√©voir des √©tapes interm√©diaires de validation."
    
    # Tester chaque type
    strategies_to_test = [
        ("Business Strategy", business_strategy),
        ("Product Strategy", product_strategy),
        ("Simple Strategy", simple_strategy)
    ]
    
    for name, strategy in strategies_to_test:
        print(f"\n{'='*50}")
        print(f"Test: {name}")
        print(f"{'='*50}")
        
        result = feedback_agent.process_feedback(strategy, feedback)
        
        if result["success"]:
            print(f"‚úÖ {name} ajust√©e avec succ√®s!")
            print(f"   Sentiment: {result['feedback_analysis']['sentiment']}")
            print(f"   √âl√©ments affect√©s: {len(result['feedback_analysis']['affected_elements'])}")
            print(f"   Ajustements: {result['processing_metadata']['adjustments_applied']}")
            print(f"   Score validation: {result['processing_metadata'].get('validation', {}).get('validation_score', 'N/A')}")
        else:
            print(f"‚ùå Erreur pour {name}: {result['error']}")

# Exemple d'utilisation avanc√©e
if __name__ == "__main__":
    # Configuration
    try:
        # Initialisation de l'agent
        feedback_agent = GeneralizedHumanFeedbackAgent()
        
        # Exemple avec une strat√©gie complexe et imbriqu√©e
        complex_strategy = {
            "meta_info": {
                "created_by": "Strategy Team",
                "version": "2.1",
                "last_updated": "2024-01-15"
            },
            "executive_summary": {
                "vision": "Devenir leader du march√© EdTech B2B",
                "mission": "Transformer l'apprentissage professionnel",
                "core_values": ["Innovation", "Qualit√©", "Collaboration"]
            },
            "market_analysis": {
                "size": {"current": "5.2B‚Ç¨", "projected_2027": "12.8B‚Ç¨"},
                "competitors": [
                    {"name": "Cornerstone", "market_share": "15%", "strength": "Enterprise"},
                    {"name": "Coursera", "market_share": "12%", "strength": "Content"}
                ],
                "opportunities": ["Remote work growth", "AI integration", "Mobile learning"],
                "threats": ["Economic downturn", "New regulations"]
            },
            "product_strategy": {
                "current_products": {
                    "momentum_platform": {
                        "description": "Plateforme d'apprentissage personnalis√©e",
                        "status": "Production",
                        "users": 50000,
                        "revenue_contribution": "70%"
                    },
                    "analytics_suite": {
                        "description": "Outils d'analyse d'apprentissage",
                        "status": "Beta",
                        "users": 5000,
                        "revenue_contribution": "15%"
                    }
                },
                "roadmap": {
                    "q1_2024": ["AI recommendations", "Mobile app v2"],
                    "q2_2024": ["Advanced analytics", "API platform"],
                    "q3_2024": ["VR integration", "Marketplace launch"],
                    "q4_2024": ["Enterprise suite", "Global expansion"]
                }
            },
            "go_to_market": {
                "target_segments": {
                    "enterprise": {
                        "size": "500+ employees",
                        "budget": "100k+/year",
                        "decision_makers": ["CHRO", "L&D Director"],
                        "sales_cycle": "6-12 months"
                    },
                    "mid_market": {
                        "size": "50-500 employees", 
                        "budget": "20k-100k/year",
                        "decision_makers": ["HR Manager", "CEO"],
                        "sales_cycle": "3-6 months"
                    }
                },
                "channels": {
                    "direct_sales": {"target": "Enterprise", "team_size": 15},
                    "inside_sales": {"target": "Mid-market", "team_size": 8},
                    "partners": {"target": "SMB", "partners_count": 25},
                    "digital": {"target": "All", "monthly_budget": "50k‚Ç¨"}
                }
            },
            "financial_projections": {
                "revenue": {
                    "2024": {"q1": 2.5, "q2": 3.2, "q3": 4.1, "q4": 5.8},
                    "2025": {"target": 25.0, "growth_rate": "150%"},
                    "2026": {"target": 50.0, "growth_rate": "100%"}
                },
                "expenses": {
                    "personnel": {"2024": 8.5, "2025": 15.0, "2026": 25.0},
                    "marketing": {"2024": 3.0, "2025": 6.0, "2026": 10.0},
                    "technology": {"2024": 2.0, "2025": 3.5, "2026": 6.0},
                    "operations": {"2024": 1.5, "2025": 2.5, "2026": 4.0}
                }
            },
            "risk_management": {
                "identified_risks": [
                    {
                        "risk": "Key talent departure",
                        "probability": "Medium",
                        "impact": "High",
                        "mitigation": "Retention programs, knowledge transfer"
                    },
                    {
                        "risk": "Competition from Big Tech",
                        "probability": "High", 
                        "impact": "High",
                        "mitigation": "Differentiation strategy, niche focus"
                    },
                    {
                        "risk": "Economic recession",
                        "probability": "Medium",
                        "impact": "Medium",
                        "mitigation": "Diversified customer base, flexible pricing"
                    }
                ]
            },
            "success_metrics": {
                "financial": {
                    "arr": {"current": 12.0, "target_2025": 25.0},
                    "gross_margin": {"current": "75%", "target": "80%"},
                    "ltv_cac": {"current": 3.2, "target": 5.0}
                },
                "product": {
                    "user_engagement": {"dau_mau": 0.35, "target": 0.45},
                    "retention": {"month_1": "85%", "month_12": "65%", "target_12": "75%"},
                    "nps": {"current": 42, "target": 60}
                },
                "operational": {
                    "team_size": {"current": 85, "target_2025": 180},
                    "customer_acquisition": {"monthly": 150, "target": 300},
                    "support_satisfaction": {"current": "4.2/5", "target": "4.5/5"}
                }
            }
        }
        
        # Feedback complexe et nuanc√©
        complex_feedback = """
        J'ai analys√© votre strat√©gie en d√©tail et j'ai plusieurs observations importantes :
        
        1. CROISSANCE TROP AGGRESSIVE: Vos projections de croissance (150% puis 100%) semblent irr√©alistes compte tenu du contexte √©conomique actuel. Les entreprises r√©duisent leurs budgets formation.
        
        2. ROADMAP PRODUIT SURCHARG√âE: Q3 2024 avec VR integration ET Marketplace launch simultan√©ment ? C'est beaucoup trop ambitieux. La VR n'est pas encore mature pour l'EdTech corporate.
        
        3. POSITIONNEMENT CONCURRENTIEL: Vous sous-estimez Google Workspace for Education et Microsoft Viva Learning qui int√®grent nativement l'apprentissage.
        
        4. SEGMENTATION CLIENT: La diff√©rence entre Enterprise et Mid-market n'est pas assez claire. Les budgets se chevauchent (100k vs 20k-100k).
        
        5. POINTS FORTS √Ä EXPLOITER: Vos m√©triques d'engagement sont excellentes (DAU/MAU 0.35). C'est votre vraie diff√©renciation face aux g√©ants.
        
        RECOMMANDATIONS:
        - Revoir les projections √† la baisse (100% puis 60% de croissance)
        - Reporter la VR √† 2025, focus sur l'AI et analytics
        - Renforcer le message diff√©renciation vs Big Tech
        - Clarifier la segmentation client
        - Capitaliser sur l'engagement utilisateur dans le messaging
        """
        
        print("üöÄ Traitement d'une strat√©gie complexe avec feedback d√©taill√©...")
        print("=" * 80)
        
        # Traitement du feedback
        result = feedback_agent.process_feedback(complex_strategy, complex_feedback)
        
        if result["success"]:
            print("‚úÖ TRAITEMENT R√âUSSI!")
            print(f"üìä ANALYSE DU FEEDBACK:")
            print(f"   ‚Ä¢ Sentiment: {result['feedback_analysis']['sentiment']}")
            print(f"   ‚Ä¢ Type: {result['feedback_analysis']['feedback_type']}")
            print(f"   ‚Ä¢ Complexit√©: {result['feedback_analysis']['complexity']}")
            print(f"   ‚Ä¢ Score de confiance: {result['feedback_analysis']['confidence_score']:.2f}")
            print(f"   ‚Ä¢ √âl√©ments affect√©s: {len(result['feedback_analysis']['affected_elements'])}")
            
            print(f"\nüîß AJUSTEMENTS APPLIQU√âS:")
            metadata = result['processing_metadata']
            print(f"   ‚Ä¢ Ajustements r√©ussis: {metadata['adjustments_applied']}/{metadata['total_adjustments_attempted']}")
            
            if 'validation' in metadata:
                validation = metadata['validation']
                print(f"\n‚úÖ VALIDATION:")
                print(f"   ‚Ä¢ Score global: {validation.get('validation_score', 'N/A')}/10")
                print(f"   ‚Ä¢ Coh√©rence: {validation.get('coherence_score', 'N/A')}")
                print(f"   ‚Ä¢ Faisabilit√©: {validation.get('feasibility_score', 'N/A')}")
                print(f"   ‚Ä¢ Am√©lioration: {validation.get('improvement_score', 'N/A')}")
            
            print(f"\nüìã D√âTAILS DES AJUSTEMENTS:")
            for i, adj in enumerate(metadata.get('adjustments_summary', [])[:5], 1):
                print(f"   {i}. {adj['path']} ({adj['type']}) - Priorit√©: {adj['priority']}")
                print(f"      Raison: {adj['reason'][:80]}...")
            
            print(f"\nüéØ PROBL√àMES IDENTIFI√âS:")
            for issue in result['feedback_analysis']['key_issues'][:3]:
                print(f"   ‚Ä¢ {issue}")
            
            print(f"\nüí° SUGGESTIONS EXTRAITES:")
            for suggestion in result['feedback_analysis']['suggestions'][:3]:
                print(f"   ‚Ä¢ {suggestion}")
            
            # Affichage d'un √©chantillon de la strat√©gie ajust√©e
            print(f"\nüìÑ APER√áU STRAT√âGIE AJUST√âE:")
            adjusted = result['adjusted_strategy']
            if 'financial_projections' in adjusted:
                print("   Projections financi√®res mises √† jour:")
                revenue_2025 = adjusted['financial_projections']['revenue']['2025']
                print(f"   ‚Ä¢ Objectif 2025: {revenue_2025.get('target', 'N/A')}M‚Ç¨ (croissance: {revenue_2025.get('growth_rate', 'N/A')})")
            
        else:
            print(f"‚ùå ERREUR: {result['error']}")
        
        # Test de l'agent avec diff√©rents types de strat√©gies
        print(f"\n{'='*80}")
        print("üß™ TESTS AVEC DIFF√âRENTS TYPES DE STRAT√âGIES")
        print("="*80)
        test_agent_with_different_strategies()
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'initialisation: {e}")
        print("V√©rifiez que la variable d'environnement GEMINI_API_KEY est d√©finie")